# Disaster Response Project

## Project Motivation
As part of a nanodegree at Udacity, this project deploys a webapp that helps classify messages that first responders get in a disaster to help organize the available resources.
## how to use it
1.- Download or clone project
2.- Run from the app folder with
> python run.py

after that you should be able to see the webapp from the url http://localhost:8050/

alternatively you can also use the data pipeline and ML pipeline used in this project to reload the data and retrain the model.

from the data folder run:
> python process_data.py disaster_messages.csv disaster_categories.csv DisasterResponse.db

and then from the models folder run
> train_classifier.py ../data/DisasterResponse.db model.pkl

## Folder Structure
```
ğŸ“¦app
 â”£ ğŸ“œapp.py : Script with dash app object initialized
 â”£ ğŸ“œcallbacks.py : Functions that update components based on user input, currently only message predictions
 â”£ ğŸ“œconstants.py : Strings to be used throughout the project
 â”£ ğŸ“œdata_utils.py : Functions for data loading
 â”£ ğŸ“œlayouts.py : app layout using dash components
 â”£ ğŸ“œrun.py : Main file that glues app, callbacks and layouts
 â”— ğŸ“œutils.py : file with functions needed in order for pickle to be able to read model.pkl
 ğŸ“¦data
 â”£ ğŸ“œDisasterResponse.db : sqlite database
 â”£ ğŸ“œdisaster_categories.csv : training messages classifications
 â”£ ğŸ“œdisaster_messages.csv : training messages
 â”— ğŸ“œprocess_data.py : Script with data pipeline to process and store messages in the db 
 ğŸ“¦models
 â”£ ğŸ“œmodel.pkl : saved model
 â”£ ğŸ“œtrain_classifier.py : Script with ML pipeline that prepares text data, trains a model on that data and saves the model
 â”— ğŸ“œutils.py : file with functions needed for pickle to be able to save the model to be later loaded from other files
```

## Webapp screenshots

![Predict Page](predict_page_screenshot.png "Predict Page")
![Data Page](data_page_screenshot.png "Data Page")
